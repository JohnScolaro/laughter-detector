% Encoding: UTF-8

@InProceedings{knox2007automatic,
  author    = {Knox, Mary Tai and Mirghafori, Nikki},
  title     = {Automatic laughter detection using neural networks.},
  booktitle = {Interspeech},
  year      = {2007},
  pages     = {2973--2976},
  file      = {:Automatic Laughter Detection Using Neural Networks.pdf:PDF},
  groups    = {Machine Learning, Classifiers, Neural Networks},
  keywords  = {Neural, Laughter, rank5, meeting, meetings},
  review    = {This paper seems to be the most recent laughter detection paper. It builds on previous work by Truong and Van Leeuwen, and uses similar features with a slightly different method to obtain better results.},
}

@InProceedings{truong2005automatic,
  author    = {Truong, Khiet P and Van Leeuwen, David A},
  title     = {Automatic detection of laughter.},
  booktitle = {Interspeech},
  year      = {2005},
  pages     = {485--488},
  file      = {:Automatic Detection of Laughter.pdf:PDF},
  groups    = {Machine Learning, Classifiers},
  keywords  = {rank4, meetings, meeting},
  review    = {Uses a PLP method with additional features to obtain ERR% from 7% to 20%.},
}

@Article{hermansky1990perceptual,
  author    = {Hermansky, Hynek},
  title     = {Perceptual linear predictive (PLP) analysis of speech},
  journal   = {the Journal of the Acoustical Society of America},
  year      = {1990},
  volume    = {87},
  number    = {4},
  pages     = {1738--1752},
  file      = {:plp_analysis_of_speech.pdf:PDF},
  groups    = {Classifiers},
  publisher = {ASA},
  review    = {Super famous paper which talks about PLP analysis.},
}

@Article{nazari2008probabilistic,
  author   = {Nazari, Mohammad and Sayadiyan, Abolghasem and Valiollahzadeh, SeyedMajid},
  title    = {Probabilistic SVM/GMM classifier for speaker-independent vowel recognition in continues speech},
  journal  = {arXiv preprint arXiv:0812.2411},
  year     = {2008},
  file     = {:Probabilistic SVM-GMM classifier for Speaker-Independant Vowel Recognition in Continues Speech.pdf:PDF},
  groups   = {Classifiers},
  keywords = {vowel, recognition, rank4},
  review   = {Vowel recognition.},
}

@InProceedings{logan2000mel,
  author    = {Logan, Beth and others},
  title     = {Mel Frequency Cepstral Coefficients for Music Modeling.},
  booktitle = {ISMIR},
  year      = {2000},
  file      = {:Mel Frequency Cepstral Coefficients for Music Modeling.pdf:PDF},
  groups    = {Classifiers},
  keywords  = {rank5},
}

@Article{hasan2004speaker,
  author   = {Hasan, Md Rashidul and Jamil, Mustafa and Rahman, Md Golam Rabbani Md Saifur and others},
  title    = {Speaker identification using mel frequency cepstral coefficients},
  journal  = {variations},
  year     = {2004},
  volume   = {1},
  number   = {4},
  file     = {:Speaker Identification.pdf:PDF},
  groups   = {Classifiers},
  keywords = {rank3},
  review   = {This article reports using MFCC's to identifiy unique individuals},
}

@InProceedings{kennedy2004laughter,
  author    = {Kennedy, L and Ellis, Daniel},
  title     = {Laughter detection in meetings},
  booktitle = {NIST ICASSP 2004 Meeting Recognition Workshop},
  year      = {2004},
  pages     = {118--121},
  file      = {:Laughter Detection in Meetings.pdf:PDF},
  keywords  = {rank2, meetings},
}

@InCollection{hepburn2013beyond,
  author = {Hepburn, Alexa and Varney, Scott},
  title  = {Beyond ((laughter)): some notes on transcription},
  year   = {2013},
  file   = {:Beyond Laughter, some notes on transcription.pdf:PDF},
  groups = {Linguistic},
}

@Article{tanaka2011acoustic,
  author   = {Tanaka, Hiroki and Campbell, Nick},
  title    = {Acoustic features of four types of laughter in natural conversational speech},
  journal  = {Prieiga per internet},
  year     = {2011},
  file     = {:Tanaka.pdf:PDF},
  groups   = {Linguistic},
  keywords = {telephone},
  url      = {http://isw3.naist.jp/IS/TL-lab/japanese/publications/icphs2011},
}

@InProceedings{trouvain2003segmenting,
  author       = {Trouvain, J{\"u}rgen},
  title        = {Segmenting phonetic units in laughter},
  booktitle    = {Proceedings of the 15th international congress of phonetic sciences},
  year         = {2003},
  pages        = {2793--2796},
  organization = {Barcelona Spain},
  file         = {:Segmenting Phonetic Units in Laughter.pdf:PDF},
  groups       = {Linguistic},
}

@Article{bachorowski2001acoustic,
  author    = {Bachorowski, Jo-Anne and Smoski, Moria J and Owren, Michael J},
  title     = {The acoustic features of human laughter},
  journal   = {The Journal of the Acoustical Society of America},
  year      = {2001},
  volume    = {110},
  number    = {3},
  pages     = {1581--1597},
  file      = {:the_acoustic_features_of_human_laughter.pdf:PDF},
  groups    = {Linguistic},
  publisher = {ASA},
}

@InProceedings{gencoglu2014recognition,
  author       = {Gencoglu, Oguzhan and Virtanen, Tuomas and Huttunen, Heikki},
  title        = {Recognition of acoustic events using deep neural networks},
  booktitle    = {Signal Processing Conference (EUSIPCO), 2014 Proceedings of the 22nd European},
  year         = {2014},
  pages        = {506--510},
  organization = {IEEE},
  groups       = {Machine Learning, Neural Networks},
}

@Article{gosztolya2016laughter,
  author  = {Gosztolya, G{\'a}bor and Beke, Andr{\'a}s and Neuberger, Tilda and T{\'o}th, L{\'a}szl{\'o}},
  title   = {Laughter Classification Using Deep Rectifier Neural Networks with a Minimal Feature Subset},
  journal = {Archives of Acoustics},
  year    = {2016},
  volume  = {41},
  number  = {4},
  pages   = {669--682},
  file    = {:[Archives of Acoustics] Laughter Classification Using Deep Rectifier Neural Networks with a Minimal Feature Subset.pdf:PDF},
  groups  = {Machine Learning, Neural Networks},
}

@Article{cosentino2016quantitative,
  author    = {Cosentino, Sarah and Sessa, Salvatore and Takanishi, Atsuo},
  title     = {Quantitative Laughter Detection, Measurement, and Classification—A Critical Survey},
  journal   = {IEEE reviews in biomedical engineering},
  year      = {2016},
  volume    = {9},
  pages     = {148--162},
  file      = {:Quantitative Laughter Detection, Measurement, and Classification - A critical Survey.pdf:PDF},
  groups    = {Linguistic},
  keywords  = {rank5},
  publisher = {IEEE},
  review    = {This is the most damn comprehensive paper on laughter I've got. It has 200+ sources and has almost everything you need to know about the physical production of laughter, and the detection. It is fantastic!},
}

@Article{truong2007automatic,
  author    = {Truong, Khiet P and Van Leeuwen, David A},
  title     = {Automatic discrimination between laughter and speech},
  journal   = {Speech Communication},
  year      = {2007},
  volume    = {49},
  number    = {2},
  pages     = {144--158},
  file      = {:Automatic Discrimination between laughter and speech.pdf:PDF},
  keywords  = {rank5, meeting, meetings},
  publisher = {Elsevier},
}

@Misc{Ellis05-rastamat,
  author   = {Daniel P. W. Ellis},
  title    = {{PLP} and {RASTA} (and {MFCC}, and inversion) in {M}atlab},
  year     = {2005},
  note     = {online web resource},
  keywords = {rank5},
  review   = {This is a website made by this guy who was a professor for 15 years, and now works for Google. It has matlab implimentations for calculating the MFCC's and PLP's for comparison. Probably will cut out a lot of time in my own work. And we is letting anyone use them.},
  url      = {http://www.ee.columbia.edu/~dpwe/resources/matlab/rastamat/},
}

@InProceedings{reuderink2008decision,
  author       = {Reuderink, Boris and Poel, Mannes and Truong, Khiet and Poppe, Ronald and Pantic, Maja},
  title        = {Decision-level fusion for audio-visual laughter detection},
  booktitle    = {International Workshop on Machine Learning for Multimodal Interaction},
  year         = {2008},
  pages        = {137--148},
  organization = {Springer},
  file         = {:detection_level_fusion_for_audio_visual_laughter_detection.pdf:PDF},
  keywords     = {rank2},
}

@InProceedings{cai2003highlight,
  author       = {Cai, Rui and Lu, Lie and Zhang, Hong-Jiang and Cai, Lian-Hong},
  title        = {Highlight sound effects detection in audio stream},
  booktitle    = {Multimedia and Expo, 2003. ICME'03. Proceedings. 2003 International Conference on},
  year         = {2003},
  volume       = {3},
  pages        = {III--37},
  organization = {IEEE},
  keywords     = {rank2},
  review       = {This paper is the one which finds applause in audio to segment large presentations.},
}

@InProceedings{yacoub2003recognition,
  author    = {Yacoub, Sherif M and Simske, Steven J and Lin, Xiaofan and Burns, John},
  title     = {Recognition of emotions in interactive voice response systems.},
  booktitle = {INTERSPEECH},
  year      = {2003},
  file      = {:recog_of_emotions_in_interactive.pdf:PDF},
  keywords  = {rank2},
  review    = {This is the paper which finds anger in audio for call centers.},
}

@Article{carter2000automatic,
  author   = {Carter, Andy},
  title    = {Automatic acoustic laughter detection},
  journal  = {Unpublished Master thesis, Keele University, Staffordshire, UK},
  year     = {2000},
  keywords = {first, masters, camera, photograph},
}

@Article{owren2007understanding,
  author   = {Owren, Michael},
  title    = {Understanding acoustics and function in spontaneous human laughter},
  journal  = {The Phonetics of Laughter},
  year     = {2007},
  pages    = {1},
  groups   = {Linguistic},
  keywords = {rank1},
  review   = {This guy is who you should quote for familierizing the terms 'bout' for a whole laugh, and 'call' for a small section of laugh, or syllable of laughter.},
}

@InProceedings{dellaert1996recognizing,
  author       = {Dellaert, Frank and Polzin, Thomas and Waibel, Alex},
  title        = {Recognizing emotion in speech},
  booktitle    = {Spoken Language, 1996. ICSLP 96. Proceedings., Fourth International Conference on},
  year         = {1996},
  volume       = {3},
  pages        = {1970--1973},
  organization = {IEEE},
  file         = {:C\:\\Users\\John\\Desktop\\Thesis Related Papers\\recognising_emotion_in_speech.pdf:PDF},
  keywords     = {emotions, speech},
}

@Article{brennan1995feeling,
  author    = {Brennan, Susan E and Williams, Maurice},
  title     = {The feeling of another's knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers},
  journal   = {Journal of memory and language},
  year      = {1995},
  volume    = {34},
  number    = {3},
  pages     = {383},
  file      = {:C\:\\Users\\John\\Desktop\\Thesis Related Papers\\the_feeling_of_anothers_knowing_prosody_and_filled_pauses_as_cues_to_listeners_about_the_metacognitive_states_of_speakers.pdf:PDF},
  publisher = {Academic Press},
}

@InProceedings{campbell2007whom,
  author       = {Campbell, Nick},
  title        = {Whom we laugh with affects how we laugh},
  booktitle    = {Proceedings of the Interdisciplinary Workshop on the Phonetics of Laughter},
  year         = {2007},
  pages        = {61--65},
  organization = {Saarbr{\"u}cken},
  file         = {:C\:\\Users\\John\\Desktop\\Thesis Related Papers\\whom_we_laugh_affects_how_we_laugh_page_61.pdf:PDF},
  keywords     = {laughter, classification, japan, telephone},
}

@Article{bachorowski2001not,
  author    = {Bachorowski, Jo-Anne and Owren, Michael J},
  title     = {Not all laughs are alike: Voiced but not unvoiced laughter readily elicits positive affect},
  journal   = {Psychological Science},
  year      = {2001},
  volume    = {12},
  number    = {3},
  pages     = {252--257},
  file      = {:not_all_laughs_are_alike.pdf:PDF},
  keywords  = {laughter, sexy, voiced, more, interested, cornell, male, female, psychology},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
}

@PhdThesis{dupont2014acoustic,
  author   = {Dupont, St{\'e}phane},
  title    = {Acoustic Laughter Processing},
  school   = {Citeseer},
  year     = {2014},
  file     = {:acoustic_laughter_processing.pdf:PDF},
  keywords = {phd, rank5},
}

@InProceedings{psutka2001comparison,
  author    = {Psutka, Josef and M{\"u}ller, Ludek and Psutka, Josef V},
  title     = {Comparison of MFCC and PLP parameterizations in the speaker independent continuous speech recognition task.},
  booktitle = {INTERSPEECH},
  year      = {2001},
  pages     = {1813--1816},
  file      = {:comparison_of_MFCC_and_PLP.pdf:PDF},
  keywords  = {comparison, mfcc, plp},
}

@InProceedings{kumar2011delta,
  author       = {Kumar, Kshitiz and Kim, Chanwoo and Stern, Richard M},
  title        = {Delta-spectral cepstral coefficients for robust speech recognition},
  booktitle    = {Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on},
  year         = {2011},
  pages        = {4784--4787},
  organization = {IEEE},
  file         = {:delta_cepstral_coefficients_for_robust_speech_recognition.pdf:PDF},
  keywords     = {nearly, all, delta, delta-delta, speech, recognition, cepstral, rank1},
  review       = {Good for the first line only really. I'm using it to quote something. "Almost all current automatic speech recognition (ASR) systems conventionally append delta and double-delta cepstral features to static cepstral features."},
}

@InProceedings{graves2013speech,
  author       = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  title        = {Speech recognition with deep recurrent neural networks},
  booktitle    = {Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},
  year         = {2013},
  pages        = {6645--6649},
  organization = {IEEE},
  file         = {:speech_recognition_with_deep_recurrent_neural_networks.pdf:PDF},
  keywords     = {toronto, google, recurrent, recurring, recurral, nets},
}

@InProceedings{zeiler2013rectified,
  author       = {Zeiler, Matthew D and Ranzato, M and Monga, Rajat and Mao, Min and Yang, Kun and Le, Quoc Viet and Nguyen, Patrick and Senior, Alan and Vanhoucke, Vincent and Dean, Jeffrey and others},
  title        = {On rectified linear units for speech processing},
  booktitle    = {Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on},
  year         = {2013},
  pages        = {3517--3521},
  organization = {IEEE},
  file         = {:on_rectifier_linear_units_for_speech_processing.pdf:PDF},
}

@Article{stowell2014automatic,
  author    = {Stowell, Dan and Plumbley, Mark D},
  title     = {Automatic large-scale classification of bird sounds is strongly improved by unsupervised feature learning},
  journal   = {PeerJ},
  year      = {2014},
  volume    = {2},
  pages     = {e488},
  file      = {:automatic_large-scale_classification_of_bird_sounds_is_strongly_improved_by_unsupervised_learning.pdf:PDF},
  publisher = {PeerJ Inc.},
}

@InProceedings{glorot2010understanding,
  author    = {Glorot, Xavier and Bengio, Yoshua},
  title     = {Understanding the difficulty of training deep feedforward neural networks},
  booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  year      = {2010},
  pages     = {249--256},
  file      = {:understanding_the_difficulty_of_training_deep_feedforward_neural_networks.pdf:PDF},
}

@Unpublished{mozilladeepspeech,
  author   = {Mozilla},
  title    = {DeepSpeech},
  keywords = {deep-learning, machine-learning, neural-networks, tensorflow, speech-recognition, speech-to-text},
  url      = {https://github.com/mozilla/DeepSpeech},
}

@Book{mehrabian1971silent,
  title     = {Silent messages},
  publisher = {Wadsworth Belmont, CA},
  year      = {1971},
  author    = {Mehrabian, Albert and others},
  volume    = {8},
}

@Article{rabiner1993fundamentals,
  author    = {Rabiner, Lawrence R and Juang, Biing-Hwang},
  title     = {Fundamentals of speech recognition},
  year      = {1993},
  file      = {:Fundamentals_of_Speech_Recognition.pdf:PDF},
  publisher = {PTR Prentice Hall},
}

@Article{hinton2012deep,
  author    = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  title     = {Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  journal   = {IEEE Signal Processing Magazine},
  year      = {2012},
  volume    = {29},
  number    = {6},
  pages     = {82--97},
  file      = {:deep_neural_networks_for_acoustic_modelling_in_speech_recognition.pdf:PDF},
  publisher = {IEEE},
}

@InCollection{lecun2012efficient,
  author    = {LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  title     = {Efficient backprop},
  booktitle = {Neural networks: Tricks of the trade},
  publisher = {Springer},
  year      = {2012},
  pages     = {9--48},
  file      = {:efficient_backprop.pdf:PDF},
}

@Misc{tensorflow2015-whitepaper,
  author = {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dan~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  title  = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
  year   = {2015},
  note   = {Software available from tensorflow.org},
  url    = {http://tensorflow.org/},
}

@Article{hannun2014deep,
  author  = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  title   = {Deep speech: Scaling up end-to-end speech recognition},
  journal = {arXiv preprint arXiv:1412.5567},
  year    = {2014},
}

@Article{bakshi1993wave,
  author    = {Bakshi, Bhavik R and Stephanopoulos, George},
  title     = {Wave-net: A multiresolution, hierarchical neural network with localized learning},
  journal   = {AIChE Journal},
  year      = {1993},
  volume    = {39},
  number    = {1},
  pages     = {57--81},
  file      = {:wavenet.pdf:PDF},
  publisher = {Wiley Online Library},
}

@InProceedings{sloetjes2008annotation,
  author    = {Sloetjes, Han and Wittenburg, Peter},
  title     = {Annotation by category: ELAN and ISO DCR.},
  booktitle = {LREC},
  year      = {2008},
}

@Article{campbell2007changes,
  author  = {Campbell, Nick},
  title   = {Changes in voice quality due to social conditions},
  journal = {ICPhS, Saarbr{\"u}cken},
  year    = {2007},
  file    = {:changes_in_voice_quality_due_to_social_conditions.pdf:PDF},
}

@Article{rees2010should,
  author    = {Rees, Charlotte E and Monrouxe, Lynn V},
  title     = {“I should be lucky ha ha ha ha”: The construction of power, identity and gender through laughter within medical workplace learning encounters},
  journal   = {Journal of Pragmatics},
  year      = {2010},
  volume    = {42},
  number    = {12},
  pages     = {3384--3399},
  file      = {:i_should_be_lucky.pdf:PDF},
  publisher = {Elsevier},
}

@Article{mik2007interpersonal,
  author    = {Mik-Meyer, Nanna},
  title     = {Interpersonal relations or jokes of social structure? Laughter in social work},
  journal   = {Qualitative Social Work},
  year      = {2007},
  volume    = {6},
  number    = {1},
  pages     = {9--26},
  file      = {:interpersonal_relations_or_jokes_of_social_structure.pdf:PDF},
  publisher = {Sage Publications London, Thousand Oaks, CA and New Delhi},
}

@Article{fry1977respiratory,
  author    = {Fry, William F and Rader, Con},
  title     = {The respiratory components of mirthful laughter.},
  journal   = {Journal of Biological Psychology},
  year      = {1977},
  publisher = {Journal of Biological Psychology},
}

@Article{scherer2009multimodal,
  author    = {Scherer, Stefan and Schwenker, Friedhelm and Campbell, Nick and Palm, G{\"u}nther},
  title     = {Multimodal laughter detection in natural discourses},
  journal   = {Human Centered Robot Systems},
  year      = {2009},
  volume    = {6},
  pages     = {111--120},
  file      = {:multimodal_laughter_detection_in_natural_discourses.pdf:PDF},
  publisher = {Springer},
}

@InProceedings{petridis2008audiovisual,
  author       = {Petridis, Stavros and Pantic, Maja},
  title        = {Audiovisual laughter detection based on temporal features},
  booktitle    = {Proceedings of the 10th international conference on Multimodal interfaces},
  year         = {2008},
  pages        = {37--44},
  organization = {ACM},
  file         = {:audiovisual_laughter_detection_based_on_temporal_features.pdf:PDF},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Linguistic\;0\;;
1 ExplicitGroup:Feature Extraction\;0\;;
1 ExplicitGroup:Machine Learning\;0\;;
2 ExplicitGroup:Neural Networks\;0\;;
}
